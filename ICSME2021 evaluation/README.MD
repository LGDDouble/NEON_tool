# NEON's evaluation

We conducted a small study to assess the NEON's capability of identifying rules useful to automatically classify app reviews along two categories, i.e.,  feature request, and  problem discovery. The study context consists of  subjects, i.e., three participants, and objects, i.e., 100 app review sentences (reported in the file [FR + PD reviews.txt](FR + PD reviews.txt)).

We processed all the 100 sentences in the sample with NEON, and obtained a list of 241 candidate grammatical rules. We then asked two subjects with Natural Language processing and parsing expertise to independently inspect the candidate rules provided by NEON and judge whether each rule was relevant (or not) for identifying sentences belonging to one of the two categories (i.e., feature request or problem discovery). 

A third annotator was involved and asked to express her independent judgment on the relevance of the rules provided by NEON in all the cases in which a disagreement between the two initial raters was observed. The results of the validation tasks are reported in the file [Relevance_Evaluation_3subjects.xlsx](Relevance_Evaluation_3subjects.xlsx). 


